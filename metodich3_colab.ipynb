{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9uRd98UFzPL"
   },
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 3. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3iOZn2wFzPQ"
   },
   "source": [
    "## Содержание методического пособия:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Что такое TensorFlow</li>\n",
    "<li>Основы синтаксиса TensorFlow</li>\n",
    "<li>Пример нейросети на TensorFlow</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sx3Su3u6FzPS"
   },
   "source": [
    "## Что такое TensorFlow\n",
    "\n",
    "TensorFlow - это фреймворк для создания ML моделей. TensorFlow предназначен в первую очередь для Deep Learning, т.е. создания современных нейросетей. Однако в TensorFlow также есть поддержка некоторых классических ML алгоритмов: K-means clustering, Random Forests, Support Vector Machines, Gaussian Mixture Model clustering, Linear/logistic regression.\n",
    "\n",
    "TensorFlow выпустила компания Google в 2015. TensorFlow - это opensource проект. На данный момент это один из основных инструментов для создания нейросетей в рабочих целях. TensorFlow позволяет создавать нейронные сети как для кластеров из большого количества вычислительных устройств, так и для устройств с относительно небольшой вычислитей мощностью, таких как смартфоны и одноплатные компьютеры.\n",
    "\n",
    "TensorFlow применяется самой компанией Google для ее поиска, почты, переводчика, распознования голоса, внутренних нужд наподобие мониторинга оборудования. TensorFlow используется различными компаниями для различных проектов связанных с компьютерным зрением, решением задач ранжирования и т.д.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBqyxNwdFzPU"
   },
   "source": [
    "## Основы синтаксиса TensorFlow\n",
    "\n",
    "Процесс создания нейросети на TensorFlow схож с разобранным нами процессом обучения нейросети на Keras. Отличее здесь в том, что здесь нам нужно прописать больше деталей в коде. \n",
    "\n",
    "Название TensorFlow означает поток тензоров. Тензоры - это массивы. Данные в компьютере предствлены часто в виде массивах и работа с этими массивами подразумевает их преобразования. Преобразования осуществляются через, к примеру, математические операции. Работа TensorFlow складывается из цепочки преобразований тензоров, т.е. данных. Сами операции осуществляющие преобразование данных представлены в TensorFlow в виде графов. Особенностью TensorFlow версии 1 является то, что сначала необходимо декларировать переменные и вычисления, которые будут совершенны над ними, а потом уже непосредственно запускать работу над данными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTDIFFhhFzPW"
   },
   "source": [
    "Давайте рассмотрим базовые вещи в синтаксисе Tensorflow 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuAYrRxLFzPY"
   },
   "source": [
    "Выведем строку Hello world, а также версию tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4Hcl_IoHv7n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in ./env/lib/python3.6/site-packages (20.0.2)\n",
      "Requirement already satisfied: tensorflow in ./env/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in ./env/lib/python3.6/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./env/lib/python3.6/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in ./env/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in ./env/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in ./env/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in ./env/lib/python3.6/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./env/lib/python3.6/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in ./env/lib/python3.6/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./env/lib/python3.6/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./env/lib/python3.6/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: gast==0.2.2 in ./env/lib/python3.6/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in ./env/lib/python3.6/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./env/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./env/lib/python3.6/site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in ./env/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py in ./env/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./env/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./env/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.3)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Downloading setuptools-46.0.0-py3-none-any.whl (582 kB)\n",
      "\u001b[K     |████████████████████████████████| 582 kB 622 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in ./env/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./env/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in ./env/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./env/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./env/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./env/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./env/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 39.0.1\n",
      "    Uninstalling setuptools-39.0.1:\n",
      "      Successfully uninstalled setuptools-39.0.1\n",
      "Successfully installed setuptools-46.0.0\n",
      "Collecting tf-nightly\n",
      "  Downloading tf_nightly-2.2.0.dev20200318-cp36-cp36m-manylinux2010_x86_64.whl (533.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 533.0 MB 26 kB/s  eta 0:00:012    |█                               | 16.5 MB 12.2 MB/s eta 0:00:43     |█████▋                          | 93.3 MB 5.8 MB/s eta 0:01:17     |█████████▌                      | 158.2 MB 5.9 MB/s eta 0:01:04     |█████████▋                      | 159.9 MB 5.9 MB/s eta 0:01:04     |████████████▉                   | 214.2 MB 4.3 MB/s eta 0:01:15     |█████████████                   | 214.8 MB 4.3 MB/s eta 0:01:15     |██████████████████████▊         | 378.5 MB 4.2 MB/s eta 0:00:37     |████████████████████████        | 400.6 MB 8.7 MB/s eta 0:00:16     |█████████████████████████       | 418.1 MB 4.9 MB/s eta 0:00:24     |██████████████████████████▎     | 437.6 MB 5.3 MB/s eta 0:00:19\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (0.9.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (1.18.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./env/lib/python3.6/site-packages (from tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (3.11.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (1.14.0)\n",
      "Collecting tb-nightly<2.3.0a0,>=2.2.0a0\n",
      "  Downloading tb_nightly-2.2.0a20200318-py3-none-any.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in ./env/lib/python3.6/site-packages (from tf-nightly) (1.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./env/lib/python3.6/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./env/lib/python3.6/site-packages (from tf-nightly) (1.27.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in ./env/lib/python3.6/site-packages (from tf-nightly) (0.34.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./env/lib/python3.6/site-packages (from tf-nightly) (3.2.0)\n",
      "Collecting tf-estimator-nightly\n",
      "  Downloading tf_estimator_nightly-2.3.0.dev2020031801-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in ./env/lib/python3.6/site-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.6/site-packages (from protobuf>=3.8.0->tf-nightly) (46.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./env/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./env/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./env/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./env/lib/python3.6/site-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.11.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.6.0.post2-py3-none-any.whl (775 kB)\n",
      "\u001b[K     |████████████████████████████████| 775 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.6/site-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./env/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in ./env/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./env/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./env/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./env/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast, astunparse, tensorboard-plugin-wit, tb-nightly, tf-estimator-nightly, tf-nightly\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 28] No space left on device\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tensorflow\n",
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad84hsn2Gwhi"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75BVCTdbFzPa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b9df2dfe41e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(tf.__version__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# msg = tf.constant('TensorFlow 2.0 Hello World')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# tf.print(msg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gb_neuralnetwork/env/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.tools'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "# msg = tf.constant('TensorFlow 2.0 Hello World')\n",
    "# tf.print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4ZN0rdqFzPh"
   },
   "source": [
    "Пример создания тензора - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VATG0L6IFzPj"
   },
   "outputs": [],
   "source": [
    "A = tf.constant([[3, 2], \n",
    "                 [5, 2]])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "van47kdAFzPp"
   },
   "source": [
    "Приме сложения тензеров - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYwJYGSvFzPr"
   },
   "outputs": [],
   "source": [
    "B = tf.constant([[9, 5], \n",
    "                 [1, 3]])\n",
    "\n",
    "AB = tf.concat(values=[A, B], axis=1)\n",
    "print(AB.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTfjbLKLFzPx"
   },
   "source": [
    "Пример изменения размерности тензора - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk_mB4qGFzPz"
   },
   "outputs": [],
   "source": [
    "tensor = tf.constant([[3, 2], \n",
    "                      [5, 2], \n",
    "                      [9, 5], \n",
    "                      [1, 3]])\n",
    "\n",
    "resh_tensor = tf.reshape(tensor = tensor, shape = [1, 8]) \n",
    "\n",
    "print(f'BEFORE {tensor.numpy()}')\n",
    "print(f'AFTER {resh_tensor.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txp4OBMXFzP6"
   },
   "source": [
    "Пример умножения матриц, одной из самых частых операций в машинном обучении - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VM7TqHlFzP8"
   },
   "outputs": [],
   "source": [
    "A = tf.constant([[3, 7], \n",
    "                 [1, 9]])\n",
    "\n",
    "\n",
    "B = tf.constant([[10, 10],\n",
    "                 [1000, 1000]])\n",
    "\n",
    "AB = tf.multiply(A, B)\n",
    "print(AB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tc9NTP1_FzQC"
   },
   "source": [
    "Функции tensorflow призваны ускорить вычисления, давайте посмотрим на следующий пример - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Классификация изображений одежды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "Давайте разберем использование tensorflow 2 на примере датасета с одеждой. В это датасете будут находиться маленькие изображения на белом фоне, такие как кросовки, футболки и прочее.\n",
    "\n",
    "В данном случае мы будем использовать High API от TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## Импортируем Fashion MNIST датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "Мы будет использовать следующий датасет -  [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) Этот датасет содержит 70,000 черно-белых изображений в 10 категориях. Изображения имеют разрешение 28x28 пикселей.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Долгое время в машинном обучение для программ Hello world использовался датасет MNIST с рукописными цифрами. Данный датасет призван несколько усложнить задачу распознования но также подходит в качестве программы Hello world.\n",
    "\n",
    "В этом датасете 60 000 тренировочных изображений и 10 000 тестовых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "Датасет содержит следующие классы:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Каждому классу обозначенному цифрой мы можем присвоить текстовое значение -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## Анализ датасета \n",
    "\n",
    "Давайте посмотрим структуры полученного массива данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRFYHB2mCaWb"
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKnCTHz4CaWg"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TMPI88iZpO2T"
   },
   "source": [
    "Проанализируем тестовую выборку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KFnYlcwCaWl"
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "Давайте взглянем на конкретный пример изображений с помощью matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "Для процесса обучения нейронной сети нам важно перевести данные из диапазона от 0 до 255 в диапазон от 0 до 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "Посмотрим первые 25 изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## Построение модели\n",
    "\n",
    "Построение нейронной сети подразумевает конфигурацию ее слоев и последующую компиляцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "### Определение слоев\n",
    "\n",
    "Давайте создадим 3 слоя нейронной сети с помощью функционала Keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "Первый слой, `tf.keras.layers.Flatten`, трасформирует двумерный массив на входе в одномерный массив.\n",
    "\n",
    "Получившиеся 784(28 x 28) входных нейрона присоединяем к полносвязному слою из 128 нейронов , которые будут использовать функцию активации relu. В выходном слое будет 10 нейронов, по числу классов, которые он должен предсказывать. В нем будет использоваться функция активации softmax и он будет давать предсказание от 0 до 1, где 1 это стопроцентная вероятность.\n",
    "\n",
    "### Компиляция модели\n",
    "\n",
    "Давайте вспомним ключевые понятия, которые нам понадобяться при компиляции:\n",
    "\n",
    "* *Loss function* — меряет как точно работает нейросеть.\n",
    "* *Optimizer* — определяет способ корректировки весов.\n",
    "* *Metrics* — определяет за какие характеристики будут отражаться в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## Тренировка модели\n",
    "\n",
    "Здесь все стандартно - данные передаются в нейросеть и сопоставляются изображения и лейблы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "### Передача данных в модель\n",
    "\n",
    "Команда непосредственно запускающая процесс обучения называется - `model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThiOOMngFzRw"
   },
   "source": [
    "В выводе выше мы следим за точностью в процессе обучения, проверяем точность на тестовых даыннх и меняем параметры нейросети если точность на тестовых данных нас не устраивает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "### Предсказания нейросети\n",
    "\n",
    "Команды ниже позволяют проверить работу натренированной ранее нейросети - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zh9yABaME29S"
   },
   "source": [
    "### Проверка предсказаний\n",
    "\n",
    "Matplotlib нам дает возможность посмотреть наше предсказание графически:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "Давайте сделаем еще несколько предсказаний - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## Использование полученной модели\n",
    "\n",
    "Давайте возьмем одно изображение из тестовой выборке и посмотрим предсказание нейронной сети - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": [
    "\n",
    "img1 = test_images[1]\n",
    "\n",
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "img = (np.expand_dims(img1,0))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": [
    "predictions_single = probability_model.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`keras.Model.predict` возвращает список списков — по одному списку для каждого предсказания в батче. Нам нужны предсказания только для одного изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tRmdq_8CaXb"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcSnl7L5FzTA"
   },
   "source": [
    "Нейросеть при хорошо подобранных параметрах должна была выдать корректное предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyurjN_EJN9P"
   },
   "outputs": [],
   "source": [
    "model1 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist1=model1.fit(train_images, train_labels, epochs=30)\n",
    "hist2=model2.fit(train_images, train_labels, epochs=30)\n",
    "hist3=model3.fit(train_images, train_labels, epochs=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8SMebNEMi37"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist1.history['accuracy'],label='model1 acc')\n",
    "plt.plot(hist2.history['accuracy'],label='model2 acc')\n",
    "plt.plot(hist3.history['accuracy'],label ='model3 acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iD4oM4JhPHWn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stCJv8cZMQZf"
   },
   "outputs": [],
   "source": [
    "# Save the model to disk.\n",
    "model1.save_weights('model1.h5')\n",
    "model2.save_weights('model2.h5')\n",
    "model3.save_weights('model3.h5')\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrz463swNcQf"
   },
   "outputs": [],
   "source": [
    "input1 = keras.layers.Input(shape=(28, 28))\n",
    "x1= keras.layers.Flatten()(input1)\n",
    "x1 = keras.layers.Dense(128, activation='relu')(x1)\n",
    "x1 =keras.layers.Dense(10)(x1)\n",
    "\n",
    "model11 =keras.models.Model(inputs=input1,outputs=x1)\n",
    "\n",
    "\n",
    "x2= keras.layers.Flatten()(input1)\n",
    "x2 = keras.layers.Dense(256, activation='relu')(x2)\n",
    "x2=keras.layers.Dense(10)(x2)\n",
    "\n",
    "model22 =keras.models.Model(inputs=input1,outputs=x2)\n",
    "\n",
    "x3= keras.layers.Flatten()(input1)\n",
    "x3 = keras.layers.Dense(256, activation='relu')(x3)\n",
    "x3=keras.layers.Dense(10)(x3)\n",
    "\n",
    "\n",
    "model33 =keras.models.Model(inputs=input1,outputs=x3)\n",
    "model11.load_weights('model1.h5')\n",
    "model22.load_weights('model2.h5')\n",
    "model33.load_weights('model3.h5')\n",
    "\n",
    "out_all = keras.layers.Average()([model11.output,model22.output,model33.output])\n",
    "out_all = keras.layers.Softmax()(out_all)\n",
    "model_all=keras.models.Model(inputs =[input1],outputs =out_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7sbO-3ra6Wh"
   },
   "outputs": [],
   "source": [
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xd5661AadF3W"
   },
   "outputs": [],
   "source": [
    "model_all.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLoBjshLbHgK"
   },
   "outputs": [],
   "source": [
    "predictions_single=model_all.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EF18AOsTbsih"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0cGPgqBc-sb"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_all.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET_usPF9ejrP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8L3JBiWewft"
   },
   "outputs": [],
   "source": [
    "plot_model(model_all,to_file='new_model-all.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6VydDuscbZC"
   },
   "source": [
    "## стек сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn7tmE-PdCoB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qnZq4X-cWLK"
   },
   "outputs": [],
   "source": [
    "# стек сетей#\n",
    "y_pred = model_all.predict(test_images)\n",
    "\n",
    "y_pred_arg = np.argmax(y_pred, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWk2XCy7grvr"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6_Y7NoEfujZ"
   },
   "outputs": [],
   "source": [
    "y_pred_arg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drCErpW-g3Qc"
   },
   "outputs": [],
   "source": [
    "y_pred_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oj4F0ibAgT6A"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test_labels,  y_pred_arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPluIfYzdqP2"
   },
   "source": [
    "Слои для объединения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VG_bkC72eeuj"
   },
   "outputs": [],
   "source": [
    "first_input = keras.layers.Input(shape=(28,28 ))\n",
    "x11= keras.layers.Flatten()(first_input)\n",
    "first_dense = keras.layers.Dense(1, )(x11)\n",
    "\n",
    "second_input = keras.layers.Input(shape=(28,28 ))\n",
    "x22= keras.layers.Flatten()(second_input)\n",
    "second_dense = keras.layers.Dense(1, )(x22)\n",
    "\n",
    "merge_one = keras.layers.concatenate([first_dense, second_dense])\n",
    "\n",
    "third_input = keras.layers.Input(shape=(28,28 ))\n",
    "x33= keras.layers.Flatten()(third_input)\n",
    "merge_two = keras.layers.concatenate([merge_one, x33])\n",
    "merge_two=keras.layers.Dense(10)(merge_two)\n",
    "merge_two = keras.layers.Softmax()(merge_two)\n",
    "\n",
    "model_stek = keras.models.Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "ada_grad = keras.optimizers.Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "model_stek .compile(optimizer=ada_grad, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZJtrdGZidwF"
   },
   "outputs": [],
   "source": [
    "plot_model(model_stek ,to_file='new_model_stek .png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-uaNKRN0ki1w"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N-nVKwhkz70"
   },
   "outputs": [],
   "source": [
    "# merge samples, two input must be same shape\n",
    "inp1 =  keras.layers.Input(shape=(10,32))\n",
    "inp2 =  keras.layers.Input(shape=(10,32))\n",
    "cc1 =  keras.layers.concatenate([inp1, inp2],axis=0) # Merge data must same row column\n",
    "output =  keras.layers.Dense(30, activation='relu')(cc1)\n",
    "model_3 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model_3.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EiclLN9k3_I"
   },
   "outputs": [],
   "source": [
    "# merge row must same column size\n",
    "inp1 =  keras.layers.Input(shape=(20,10))\n",
    "inp2 =  keras.layers.Input(shape=(32,10))\n",
    "cc1 =  keras.layers.concatenate([inp1, inp2],axis=1)\n",
    "output =  keras.layers.Dense(30, activation='relu')(cc1)\n",
    "model_4 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model_4.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1q7tqJGMk6Zz"
   },
   "outputs": [],
   "source": [
    "# merge column must same row size\n",
    "inp1 =  keras.layers.Input(shape=(10,20))\n",
    "inp2 =  keras.layers.Input(shape=(10,32))\n",
    "cc1 =  keras.layers.concatenate([inp1, inp2],axis=2)\n",
    "output =  keras.layers.Dense(30, activation='relu')(cc1)\n",
    "model_5 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7ek0hWkmFv3"
   },
   "outputs": [],
   "source": [
    "inp1 =  keras.layers.Input(shape=(10,32))\n",
    "inp2 =  keras.layers.Input(shape=(10,32))\n",
    "cc1 =  keras.layers.Add()([inp1, inp2]) # Merge data must same row column\n",
    "output =  keras.layers.Dense(30, activation='relu')(cc1)\n",
    "model_31 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model_31.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5AGTEbJomXER"
   },
   "outputs": [],
   "source": [
    "inp1 =  keras.layers.Input(shape=(10,32))\n",
    "inp2 =  keras.layers.Input(shape=(10,32))\n",
    "cc1 =  keras.layers.Multiply()([inp1, inp2]) # Merge data must same row column\n",
    "output =  keras.layers.Dense(30, activation='relu')(cc1)\n",
    "model_32 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model_32.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oh4useS4mioy"
   },
   "outputs": [],
   "source": [
    "inp1 =  keras.layers.Input(shape=(10,32))\n",
    "inp2 =  keras.layers.Input(shape=(10,32))\n",
    "cc1 =  keras.layers.Subtract()([inp1, inp2]) # Merge data must same row column\n",
    "output =  keras.layers.Dense(30, activation='relu')(cc1)\n",
    "model_3 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model_3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qG-DkLPsnh0q"
   },
   "outputs": [],
   "source": [
    "def myFunc(C):\n",
    "  \n",
    "  return C[0]*C[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KU5MFJ9KnNG9"
   },
   "outputs": [],
   "source": [
    "\n",
    "inp1 =  keras.layers.Input(shape=(10,32))\n",
    "inp2 =  keras.layers.Input(shape=(10,32))\n",
    "cc1 =  keras.layers.Subtract()([inp1, inp2]) \n",
    "cross2 = keras.layers.Lambda(myFunc)([cc1,cc1])\n",
    "output =  keras.layers.Dense(30, activation='relu')(cross2)\n",
    "model_35 =  keras.models.Model(inputs=[inp1, inp2], outputs=output)\n",
    "model_35.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZyy2UhoFzTB"
   },
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте обучить нейронную сеть на TensorFlow 2 на любом датасете imdb_reviews. \n",
    "        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?<br><br>\n",
    "    </li>\n",
    "    <li>*2. Поработайте с документацией TensorFlow 2. Найдите полезные команды не разобранные на уроке.</li>\n",
    "    \n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNZ6hZcMFzTE"
   },
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>www.tensorflow.org/api_docs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q64Z2Kr_FzTF"
   },
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://www.tensorflow.org/</li>\n",
    "    <li>https://www.tensorflow.org/tutorials/keras/classification</li>\n",
    "    <li>Singh P., Manure A. - Learn TensorFlow 2.0 - 2020</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Википедия</li>\n",
    "    \n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "metodich3.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
